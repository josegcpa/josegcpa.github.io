<!DOCTYPE html>
<html>

<head>

<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>Computer vision in Python - cheat sheet</title>


<style type="text/css">
body {
  font-family: Helvetica, arial, sans-serif;
  font-size: 14px;
  line-height: 1.6;
  padding-top: 10px;
  padding-bottom: 10px;
  background-color: white;
  padding: 30px; }

body > *:first-child {
  margin-top: 0 !important; }
body > *:last-child {
  margin-bottom: 0 !important; }

a {
  color: #4183C4; }
a.absent {
  color: #cc0000; }
a.anchor {
  display: block;
  padding-left: 30px;
  margin-left: -30px;
  cursor: pointer;
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0; }

h1, h2, h3, h4, h5, h6 {
  margin: 20px 0 10px;
  padding: 0;
  font-weight: bold;
  -webkit-font-smoothing: antialiased;
  cursor: text;
  position: relative; }

h1:hover a.anchor, h2:hover a.anchor, h3:hover a.anchor, h4:hover a.anchor, h5:hover a.anchor, h6:hover a.anchor {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA09pVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMy1jMDExIDY2LjE0NTY2MSwgMjAxMi8wMi8wNi0xNDo1NjoyNyAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvIiB4bWxuczp4bXBNTT0iaHR0cDovL25zLmFkb2JlLmNvbS94YXAvMS4wL21tLyIgeG1sbnM6c3RSZWY9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9zVHlwZS9SZXNvdXJjZVJlZiMiIHhtcDpDcmVhdG9yVG9vbD0iQWRvYmUgUGhvdG9zaG9wIENTNiAoMTMuMCAyMDEyMDMwNS5tLjQxNSAyMDEyLzAzLzA1OjIxOjAwOjAwKSAgKE1hY2ludG9zaCkiIHhtcE1NOkluc3RhbmNlSUQ9InhtcC5paWQ6OUM2NjlDQjI4ODBGMTFFMTg1ODlEODNERDJBRjUwQTQiIHhtcE1NOkRvY3VtZW50SUQ9InhtcC5kaWQ6OUM2NjlDQjM4ODBGMTFFMTg1ODlEODNERDJBRjUwQTQiPiA8eG1wTU06RGVyaXZlZEZyb20gc3RSZWY6aW5zdGFuY2VJRD0ieG1wLmlpZDo5QzY2OUNCMDg4MEYxMUUxODU4OUQ4M0REMkFGNTBBNCIgc3RSZWY6ZG9jdW1lbnRJRD0ieG1wLmRpZDo5QzY2OUNCMTg4MEYxMUUxODU4OUQ4M0REMkFGNTBBNCIvPiA8L3JkZjpEZXNjcmlwdGlvbj4gPC9yZGY6UkRGPiA8L3g6eG1wbWV0YT4gPD94cGFja2V0IGVuZD0iciI/PsQhXeAAAABfSURBVHjaYvz//z8DJYCRUgMYQAbAMBQIAvEqkBQWXI6sHqwHiwG70TTBxGaiWwjCTGgOUgJiF1J8wMRAIUA34B4Q76HUBelAfJYSA0CuMIEaRP8wGIkGMA54bgQIMACAmkXJi0hKJQAAAABJRU5ErkJggg==) no-repeat 10px center;
  text-decoration: none; }

h1 tt, h1 code {
  font-size: inherit; }

h2 tt, h2 code {
  font-size: inherit; }

h3 tt, h3 code {
  font-size: inherit; }

h4 tt, h4 code {
  font-size: inherit; }

h5 tt, h5 code {
  font-size: inherit; }

h6 tt, h6 code {
  font-size: inherit; }

h1 {
  font-size: 28px;
  color: black; }

h2 {
  font-size: 24px;
  border-bottom: 1px solid #cccccc;
  color: black; }

h3 {
  font-size: 18px; }

h4 {
  font-size: 16px; }

h5 {
  font-size: 14px; }

h6 {
  color: #777777;
  font-size: 14px; }

p, blockquote, ul, ol, dl, li, table, pre {
  margin: 15px 0; }

hr {
  background: transparent url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAYAAAAECAYAAACtBE5DAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAyJpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvIiB4bWxuczp4bXBNTT0iaHR0cDovL25zLmFkb2JlLmNvbS94YXAvMS4wL21tLyIgeG1sbnM6c3RSZWY9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9zVHlwZS9SZXNvdXJjZVJlZiMiIHhtcDpDcmVhdG9yVG9vbD0iQWRvYmUgUGhvdG9zaG9wIENTNSBNYWNpbnRvc2giIHhtcE1NOkluc3RhbmNlSUQ9InhtcC5paWQ6OENDRjNBN0E2NTZBMTFFMEI3QjRBODM4NzJDMjlGNDgiIHhtcE1NOkRvY3VtZW50SUQ9InhtcC5kaWQ6OENDRjNBN0I2NTZBMTFFMEI3QjRBODM4NzJDMjlGNDgiPiA8eG1wTU06RGVyaXZlZEZyb20gc3RSZWY6aW5zdGFuY2VJRD0ieG1wLmlpZDo4Q0NGM0E3ODY1NkExMUUwQjdCNEE4Mzg3MkMyOUY0OCIgc3RSZWY6ZG9jdW1lbnRJRD0ieG1wLmRpZDo4Q0NGM0E3OTY1NkExMUUwQjdCNEE4Mzg3MkMyOUY0OCIvPiA8L3JkZjpEZXNjcmlwdGlvbj4gPC9yZGY6UkRGPiA8L3g6eG1wbWV0YT4gPD94cGFja2V0IGVuZD0iciI/PqqezsUAAAAfSURBVHjaYmRABcYwBiM2QSA4y4hNEKYDQxAEAAIMAHNGAzhkPOlYAAAAAElFTkSuQmCC) repeat-x 0 0;
  border: 0 none;
  color: #cccccc;
  height: 4px;
  padding: 0;
}

body > h2:first-child {
  margin-top: 0;
  padding-top: 0; }
body > h1:first-child {
  margin-top: 0;
  padding-top: 0; }
  body > h1:first-child + h2 {
    margin-top: 0;
    padding-top: 0; }
body > h3:first-child, body > h4:first-child, body > h5:first-child, body > h6:first-child {
  margin-top: 0;
  padding-top: 0; }

a:first-child h1, a:first-child h2, a:first-child h3, a:first-child h4, a:first-child h5, a:first-child h6 {
  margin-top: 0;
  padding-top: 0; }

h1 p, h2 p, h3 p, h4 p, h5 p, h6 p {
  margin-top: 0; }

li p.first {
  display: inline-block; }
li {
  margin: 0; }
ul, ol {
  padding-left: 30px; }

ul :first-child, ol :first-child {
  margin-top: 0; }

dl {
  padding: 0; }
  dl dt {
    font-size: 14px;
    font-weight: bold;
    font-style: italic;
    padding: 0;
    margin: 15px 0 5px; }
    dl dt:first-child {
      padding: 0; }
    dl dt > :first-child {
      margin-top: 0; }
    dl dt > :last-child {
      margin-bottom: 0; }
  dl dd {
    margin: 0 0 15px;
    padding: 0 15px; }
    dl dd > :first-child {
      margin-top: 0; }
    dl dd > :last-child {
      margin-bottom: 0; }

blockquote {
  border-left: 4px solid #dddddd;
  padding: 0 15px;
  color: #777777; }
  blockquote > :first-child {
    margin-top: 0; }
  blockquote > :last-child {
    margin-bottom: 0; }

table {
  padding: 0;border-collapse: collapse; }
  table tr {
    border-top: 1px solid #cccccc;
    background-color: white;
    margin: 0;
    padding: 0; }
    table tr:nth-child(2n) {
      background-color: #f8f8f8; }
    table tr th {
      font-weight: bold;
      border: 1px solid #cccccc;
      margin: 0;
      padding: 6px 13px; }
    table tr td {
      border: 1px solid #cccccc;
      margin: 0;
      padding: 6px 13px; }
    table tr th :first-child, table tr td :first-child {
      margin-top: 0; }
    table tr th :last-child, table tr td :last-child {
      margin-bottom: 0; }

img {
  max-width: 100%; }

span.frame {
  display: block;
  overflow: hidden; }
  span.frame > span {
    border: 1px solid #dddddd;
    display: block;
    float: left;
    overflow: hidden;
    margin: 13px 0 0;
    padding: 7px;
    width: auto; }
  span.frame span img {
    display: block;
    float: left; }
  span.frame span span {
    clear: both;
    color: #333333;
    display: block;
    padding: 5px 0 0; }
span.align-center {
  display: block;
  overflow: hidden;
  clear: both; }
  span.align-center > span {
    display: block;
    overflow: hidden;
    margin: 13px auto 0;
    text-align: center; }
  span.align-center span img {
    margin: 0 auto;
    text-align: center; }
span.align-right {
  display: block;
  overflow: hidden;
  clear: both; }
  span.align-right > span {
    display: block;
    overflow: hidden;
    margin: 13px 0 0;
    text-align: right; }
  span.align-right span img {
    margin: 0;
    text-align: right; }
span.float-left {
  display: block;
  margin-right: 13px;
  overflow: hidden;
  float: left; }
  span.float-left span {
    margin: 13px 0 0; }
span.float-right {
  display: block;
  margin-left: 13px;
  overflow: hidden;
  float: right; }
  span.float-right > span {
    display: block;
    overflow: hidden;
    margin: 13px auto 0;
    text-align: right; }

code, tt {
  margin: 0 2px;
  padding: 0 5px;
  white-space: nowrap;
  border: 1px solid #eaeaea;
  background-color: #f8f8f8;
  border-radius: 3px; }

pre code {
  margin: 0;
  padding: 0;
  white-space: pre;
  border: none;
  background: transparent; }

.highlight pre {
  background-color: #f8f8f8;
  border: 1px solid #cccccc;
  font-size: 13px;
  line-height: 19px;
  overflow: auto;
  padding: 6px 10px;
  border-radius: 3px; }

pre {
  background-color: #f8f8f8;
  border: 1px solid #cccccc;
  font-size: 13px;
  line-height: 19px;
  overflow: auto;
  padding: 6px 10px;
  border-radius: 3px; }
  pre code, pre tt {
    background-color: transparent;
    border: none; }

sup {
    font-size: 0.83em;
    vertical-align: super;
    line-height: 0;
}

kbd {
  display: inline-block;
  padding: 3px 5px;
  font-size: 11px;
  line-height: 10px;
  color: #555;
  vertical-align: middle;
  background-color: #fcfcfc;
  border: solid 1px #ccc;
  border-bottom-color: #bbb;
  border-radius: 3px;
  box-shadow: inset 0 -1px 0 #bbb
}

* {
	-webkit-print-color-adjust: exact;
}
@media screen and (min-width: 914px) {
    body {
        width: 854px;
        margin:0 auto;
    }
}
@media print {
	table, pre {
		page-break-inside: avoid;
	}
	pre {
		word-wrap: break-word;
	}
}
</style>

<style type="text/css">
/**
 * prism.js tomorrow night eighties for JavaScript, CoffeeScript, CSS and HTML
 * Based on https://github.com/chriskempson/tomorrow-theme
 * @author Rose Pritchard
 */

code[class*="language-"],
pre[class*="language-"] {
	color: #ccc;
	background: none;
	font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
	text-align: left;
	white-space: pre;
	word-spacing: normal;
	word-break: normal;
	word-wrap: normal;
	line-height: 1.5;

	-moz-tab-size: 4;
	-o-tab-size: 4;
	tab-size: 4;

	-webkit-hyphens: none;
	-moz-hyphens: none;
	-ms-hyphens: none;
	hyphens: none;

}

/* Code blocks */
pre[class*="language-"] {
	padding: 1em;
	margin: .5em 0;
	overflow: auto;
}

:not(pre) > code[class*="language-"],
pre[class*="language-"] {
	background: #2d2d2d;
}

/* Inline code */
:not(pre) > code[class*="language-"] {
	padding: .1em;
	border-radius: .3em;
	white-space: normal;
}

.token.comment,
.token.block-comment,
.token.prolog,
.token.doctype,
.token.cdata {
	color: #999;
}

.token.punctuation {
	color: #ccc;
}

.token.tag,
.token.attr-name,
.token.namespace,
.token.deleted {
	color: #e2777a;
}

.token.function-name {
	color: #6196cc;
}

.token.boolean,
.token.number,
.token.function {
	color: #f08d49;
}

.token.property,
.token.class-name,
.token.constant,
.token.symbol {
	color: #f8c555;
}

.token.selector,
.token.important,
.token.atrule,
.token.keyword,
.token.builtin {
	color: #cc99cd;
}

.token.string,
.token.char,
.token.attr-value,
.token.regex,
.token.variable {
	color: #7ec699;
}

.token.operator,
.token.entity,
.token.url {
	color: #67cdcc;
}

.token.important,
.token.bold {
	font-weight: bold;
}
.token.italic {
	font-style: italic;
}

.token.entity {
	cursor: help;
}

.token.inserted {
	color: green;
}
</style>

<style type="text/css">
pre.line-numbers {
	position: relative;
	padding-left: 3.8em;
	counter-reset: linenumber;
}

pre.line-numbers > code {
	position: relative;
}

.line-numbers .line-numbers-rows {
	position: absolute;
	pointer-events: none;
	top: 0;
	font-size: 100%;
	left: -3.8em;
	width: 3em; /* works for line-numbers below 1000 lines */
	letter-spacing: -1px;
	border-right: 1px solid #999;

	-webkit-user-select: none;
	-moz-user-select: none;
	-ms-user-select: none;
	user-select: none;

}

	.line-numbers-rows > span {
		pointer-events: none;
		display: block;
		counter-increment: linenumber;
	}

		.line-numbers-rows > span:before {
			content: counter(linenumber);
			color: #999;
			display: block;
			padding-right: 0.8em;
			text-align: right;
		}
</style>

<style type="text/css">
div.prism-show-language {
	position: relative;
}

div.prism-show-language > div.prism-show-language-label {
	color: black;
	background-color: #CFCFCF;
	display: inline-block;
	position: absolute;
	bottom: auto;
	left: auto;
	top: 0;
	right: 0;
	width: auto;
	height: auto;
	font-size: 0.9em;
	border-radius: 0 0 0 5px;
	padding: 0 0.5em;
	text-shadow: none;
	z-index: 1;
	-webkit-box-shadow: none;
	-moz-box-shadow: none;
	box-shadow: none;
	-webkit-transform: none;
	-moz-transform: none;
	-ms-transform: none;
	-o-transform: none;
	transform: none;
}
</style>


</head>

<body>

<h1 id="toc_0">Computer vision - concepts</h1>

<p>Keep in mind that this will never be better than the documentation for either package. If you get stuck somewhere just call for help or <a href="https://stackoverflow.com">pray</a>.</p>

<h2 id="toc_1">Image I/O and visualization</h2>

<h3 id="toc_2">Open CV</h3>

<p>Using <code>OpenCV</code>, images are loaded as <code>numpy</code> arrays.</p>

<div><pre class="line-numbers"><code class="language-python">import cv2

####################
# Opening an image #
####################

image_path = &#39;/home/josegcpa/folder/example.png&#39;
mode_color = cv2.IMREAD_COLOR 
mode_grayscale = cv2.IMREAD_GRAYSCALE
image_color = cv2.imread(image_path,mode_color)
image_grayscale = cv2.imread(image_path,mode_grayscale)
# OpenCV uses the BGR format, so to work with RGB we need to convert it
image_rgb = cv2.cvtColor(image_color,cv2.COLOR_BGR2RGB)

########################
# Visualizing an image #
########################

# OpenCV is very powerful, especially if we are planning on building more 
# complex applications. This makes some lower level operations slightly
# more complicated.
window_name = &#39;image&#39;
cv2.imshow(window_name,image_color)
cv2.waitKey(0)
cv2.destroyAllWindows()

###################
# Saving an image #
###################

output_path = &#39;amazing_image.png&#39;
cv2.imwrite(output_path,image_color)</code></pre></div>

<h3 id="toc_3">scikit-image</h3>

<p>Using <code>scikit-image</code>, as with OpenCV, images are loaded as <code>numpy</code> arrays. </p>

<div><pre class="line-numbers"><code class="language-python">from skimage.io import imread,imshow,imsave 

####################
# Opening an image #
####################

image_path = &#39;/home/josegcpa/folder/example.png&#39;
image_color = imread(image_path)

# Convenience function to create a generator with all images in matching
# a pattern
from skimage.io import imread_collection
images = imread_collection(&#39;/home/josegcpa/folder/*.png&#39;)

########################
# Visualizing an image #
########################

imshow(image_color)

###################
# Saving an image #
###################

output_path = &#39;amazing_image.png&#39;
imsave(output_path,image_color)</code></pre></div>

<h3 id="toc_4">Pillow</h3>

<p><code>Pillow</code> uses its own type of objects and loads images as <code>Image</code> objects, which features some handy methods. It is not the most popular for large pipelines, but it is useful for quickly checking something in an image through Python. </p>

<div><pre class="line-numbers"><code class="language-python">from PIL import Image 

####################
# Opening an image #
####################

image_path = &#39;/home/josegcpa/folder/example.png&#39;
image_color = Image.open(image_path)

########################
# Visualizing an image #
########################

image_color.show()

###################
# Saving an image #
###################

output_path = &#39;amazing_image.png&#39;
image_color.save(output_path)

################################
# Image-numpy array conversion #
################################

# Image object to numpy array
import numpy as np
image_array = np.array(image_color)

# numpy array to Image object
image_color = Image.fromarray(image_array)</code></pre></div>

<h2 id="toc_5">Arrays</h2>

<h3 id="toc_6">Why arrays?</h3>

<p>You should always aim to use <code>numpy</code> arrays since a lot of <code>python</code> functions are already implemented for these arrays. Keep in mind that an image is typically a three-dimensional array if it has more than one channel (Height * Width * Channel), but is a two-dimensional array if it has only one channel (Height * Width).</p>

<h3 id="toc_7">Arrays 101</h3>

<div><pre class="line-numbers"><code class="language-python">import numpy as np
from skimage.io import imread,imshow,imsave 

image_path = &#39;/home/josegcpa/folder/example.png&#39;
image = imread(image_path) # an array

print(image.shape) # array dimensions
print(image.size) # total number of elements in the array
print(image.dtype) # data type

# Indexing 
image[0] # first row of the array
image[1,4] # element(s) on the first column, 4th column
image[0,:] # first row of the array
image[:,0] # first column of the array
image[0:10,:] # first 10 rows
image[image &gt; 10] # a boolean mask that is true for array elements &gt; 10
# (which is basically what thresholding is)

# Useful operations
image_times_two = image * 2
image_squared = image ** 2
image_minus_ten = image - 10 # numpy broadcasts if possible

average = np.mean(average) # mean over all elements
average = np.mean(average,axis=2) # average over 3rd dimension (channels)
# averaging color channels is the same as grayscaling an image
std = np.std(average) # standard deviation over all elements
std = np.std(average,axis=2) # standard deviation over all 3rd dimension

# Probably-not-useful-but-fun-to-know operations
merged_images = image_1 * 0.7 + image_2 * 0.3</code></pre></div>

<h2 id="toc_8">Image operations - theory behind convolutions, transformations <em>and so on and so forth</em></h2>

<p>This will focus mostly on the theory behind each step. The reason for this is to allow each one of you to go and find the solutions for yourselves. For <code>python</code>, I recommend a mixture of both <code>OpenCV</code> and <code>scikit-image</code> since they operate mostly on <code>numpy</code> arrays.</p>

<h3 id="toc_9">Convolutions</h3>

<p><strong>Protip:</strong> apply some of these methods yourself (i.e. build your own operators and apply them on a 2D image) using the <code>convolve</code> function from <code>scipy.ndimage.filters</code> (read more about it <a href="https://docs.scipy.org/doc/scipy-0.15.1/reference/generated/scipy.ndimage.filters.convolve.html">here</a>):</p>

<div><pre class="line-numbers"><code class="language-python">import convolve from scipy.ndimage.filters

some_filter = np.random.normal(size=(3,3)) # a 3 * 3 convolutional filter
convolve(some_image,some_filter)
</code></pre></div>

<p><center></p>

<table>
<thead>
<tr>
<th>0</th>
<th>-1</th>
<th>0</th>
</tr>
</thead>

<tbody>
<tr>
<td><strong>-1</strong></td>
<td><strong>4</strong></td>
<td><strong>-1</strong></td>
</tr>
<tr>
<td><strong>0</strong></td>
<td><strong>-1</strong></td>
<td><strong>0</strong></td>
</tr>
</tbody>
</table>

<p><em>A Laplacian convolutional filter.</em></p>

<p></center></p>

<p><strong>Convolutions</strong> are, essentially, the weighted summation of neighbouring pixels. Consider the following example, where a convolutional filter is used over an <q>image</q> to obtain new results. The weights in this weighted sum are described by the convolutional filter/operator/kernel.</p>

<p><center></p>

<p><img src="https://ujwlkarn.files.wordpress.com/2016/07/convolution_schematic.gif" alt=""></p>

<p></center></p>

<p>In <strong>most</strong> deep learning applications for image analysis, stacked convolutional filters spread across several layers are learned (optimized for a given task) through gradient-based methods. However, learning these convolutional filters is not trivial with low computational power. As such, instead of learning these convolutions, we use off-the-shelf convolutions (<a href="https://en.wikipedia.org/wiki/Sobel_operator">Sobel operators</a> (<a href="https://www.youtube.com/watch?v=uihBwtPIBxM">a very cool video on this</a>) and <a href="https://en.wikipedia.org/wiki/Discrete_Laplace_operator">the discrete Laplace operator</a> are some examples of this and can be used for edge detection). </p>

<h3 id="toc_10">Smoothing images</h3>

<p>Smoothing can be considered a good and fairly standard step in preprocessing images for feature extraction. Smoothing takes care of most of the noise in the image (considering that noise is a random variation of brightness or color intensity in an image). </p>

<p>To get rid of noise, smoothing can be done using a convolutional kernel (i.e. a 3 * 3 matrix) to convolve the image. This kernel can be:</p>

<ul>
<li>An average kernel (each element of the kernel is equally weighted and the sum of all kernel elements \(=1\))</li>
<li>A Gaussian kernel (the weights are calculated using a Gaussian function centered in the center of the kernel)</li>
<li>A median kernel (instead of having a precise definition, this kernel calculates the median for each area)</li>
</ul>

<p>Apart from these, bilateral filtering is also quite popular since it preserves edges. To do this, it also calculates a weighted average of the pixels, but the kernel&rsquo;s weights are calculated based on Euclidean distance (as the Gaussian kernel) and on color distance.</p>

<h3 id="toc_11">Thresholding</h3>

<p>Image thresholding describes a set of methods that are used to classify pixels in a binary way. To do so, we can use an arbitrary value (all pixels above or below a certain value) or more adaptive methods. The latter (i.e. more adaptive methods) includes:</p>

<ul>
<li>Otsu threshold - the value for thresholding is determined using the intensity histogram as the value that best separates the histogram assuming that the intensities are bimodal (<strong>note</strong>: this is probably not true for most cases)</li>
<li>Adaptive thresholding - instead of determining a threshold for the entire image, a sliding window determines local thresholds (a mean kernel or a Gaussian kernel can be used, for example)</li>
</ul>

<h3 id="toc_12">Morphological operations</h3>

<p>Morphological operations work on binary images. They are a set of nonlinear operations that end up affecting the shape of an image, hence the name. They consist on applying a binary kernel of a given size and determining a new value for the pixel in the center (similar to convolutions). However, they are much more simple:</p>

<ul>
<li>Erosion - if all pixels in the kernel are \(1\), then the new value for the pixel will be \(1\). Otherwise it will be \(0\)</li>
<li>Dilation - if all pixels in the kernel are \(0\), then the new value for the pixel will be \(0\). Otherwise it will be \(1\)</li>
<li>Opening - an erosion followed by a dilation (useful to get rid of lonely positive pixels)</li>
<li>Closing - a dilation followed by an erosion (useful to get rid of lonely negative pixels)</li>
<li>Morphological gradient - \(dilation(image) - erosion(image)\) (useful for quick edge detection in binary images)</li>
<li>Tophat - \(image - opening(image)\) (useful to get small element from the image)</li>
<li>Blackhat - \(closing(image) - image\)</li>
</ul>

<h3 id="toc_13">Edge detection and gradients</h3>

<p>Edges, in computer vision, can be defined as regions with a high gradient<sup>1</sup>. While gradients are usually continuous, image analysis grew as a field with the potential to be practically very complex, but applications demanded highly efficient (i.e. fast <em>and</em> accurate) methods. As mentioned, Sobel and Laplacian operators can be used to detect edges because they are fast and fairly accurate ways of approximating gradients. </p>

<p><em>y tho?</em></p>

<p>Because they are built to signal pixels that are in the middle of a large change in intensity values. While the Laplace operator is pretty much invariant to direction (which also makes it weaker), the Sobel operator allows us to calculate the direction by calculating the gradients for \(x\) and \(y\) separately. The protocol for Sobel edge detection is as follows:</p>

<ol>
<li>Convolve an image with the \(x\) Sobel operator and the \(y\) Sobel operator (what are these <em>mysterious</em> and <em>ellusive</em> operators? Wouldn&rsquo;t it be great if there was some way of searching for something on the internet?)</li>
<li>Calculate the gradient intensity using the \(x\) and \(y\) gradients (\(\nabla=\sqrt{\nabla x^2+\nabla y^2}\))</li>
<li>Calculate the direction (i.e. angle) of the gradients \(angle=tan^-1(\frac{\nabla x}{\nabla y})\)</li>
</ol>

<p>Apart from the simple enough Sobel and Laplace operators, in 1986 the Canny edge detector was created, which is more generalizable and generally better than simpler methods. The protocol for the Canny edge detector is simple enough:</p>

<ol>
<li>Noise reduction </li>
<li>Finding the intensity gradient</li>
<li>Non-maximum suppression - we will get a lot of spurious edges, so we will need to get rid of them and keep <strong>thin</strong> edges which are very probably <strong>actual</strong> edges (there are functions for this, but an implementation is not complicated)</li>
<li>Apply a double threshold method on the gradient intensity map, with a minimum value (min<u>val) and a maximum value (max</u>value):

<ol>
<li>All pixels above max<u>value are edges for sure and all those below min</u>value are not edges for sure</li>
<li>The clasification of pixels with gradient intensity values between min<u>val and max</u>val depends on whether they are or not connected to a pixel that is above max_val </li>
</ol></li>
</ol>

<p><sup>1</sup> in a cartesian system, for a function \(f(x,y)\), the gradient \(\nabla(f)\) can be calculated as \(\nabla(f) = \frac{\partial f}{\partial x}i + \frac{\partial f}{\partial y}j\), with \(i\) and \(j\) as the unit vectors in the \(x\) and \(y\) direction, respectively</p>

<h3 id="toc_14">Image pyramids</h3>

<p>Image pyramids are stacked representations of images at different resolutions. They are built using a single image, which is downsampled consecutively for \(n\) levels for a given factor. These are useful to extract features at different resolutions, which is useful to identify <q>important</q> features, defined as features which are present at different resolutions.</p>

<h3 id="toc_15">Contour detection</h3>

<p>A <strong>contour</strong> is defined as the boundary of an object in an image that has the same intensity. This is useful when we need to extract some features from objects detected in an image after thresholding or segmentation. These features can be as simple as the size (i.e. area), perimeter and moments of the contour, or approximated polygons, convex hulls and circles that enclose the contour. </p>

<p>With contours we can also detect minimum and maximum values for the original image and the orientation of the object, among other things.</p>

<h3 id="toc_16">Image segmentation - watershed</h3>

<p>Image segmentation, fundamentally, is determining a mask that assigns all pixels belonging to an object or set of objects as positive and all other pixels as negative. Thresholding techniques can be used to do this, but if we are also interested in sepparating these objects, we have to perform some additional steps. Watershed is a generallized approach to do this. It can be defined with a simple protocol:</p>

<ol>
<li>Obtain a binary image <em>via</em> your favourite process (thresholding <em>might</em> work)</li>
<li>Determine the sure foreground (regions that are very likely to belong to the objects we are interested in segmenting) and the sure background (regions that encompass not only the object, but an area surrounding it)</li>
<li>Get the unknown region as the difference between the sure background and the sure foreground</li>
<li>Use a distance transformation on the sure foreground - this reassigns positive values in the image as the distance to background (pixels in the center of an object will have higher values - we can use this to detect centers)</li>
<li>Detect local peaks on the distance transformation to get the center pixel of each object</li>
<li>Detected all connected components (objects) on the image (<code>cv2.connectedComponents</code>) using the image obtained in step 5</li>
<li>Perform watershedding (finally!) to get the separated objects. Watershed for image processing is usually a flood fill process - you start with a seed (the components detected in step 6) and <q>fill it</q> (add pixels to this object) until it runs into background or other object</li>
</ol>



<script type="text/javascript">
var _self="undefined"!=typeof window?window:"undefined"!=typeof WorkerGlobalScope&&self instanceof WorkerGlobalScope?self:{},Prism=function(){var e=/\blang(?:uage)?-(\w+)\b/i,t=0,n=_self.Prism={util:{encode:function(e){return e instanceof a?new a(e.type,n.util.encode(e.content),e.alias):"Array"===n.util.type(e)?e.map(n.util.encode):e.replace(/&/g,"&amp;").replace(/</g,"&lt;").replace(/\u00a0/g," ")},type:function(e){return Object.prototype.toString.call(e).match(/\[object (\w+)\]/)[1]},objId:function(e){return e.__id||Object.defineProperty(e,"__id",{value:++t}),e.__id},clone:function(e){var t=n.util.type(e);switch(t){case"Object":var a={};for(var r in e)e.hasOwnProperty(r)&&(a[r]=n.util.clone(e[r]));return a;case"Array":return e.map&&e.map(function(e){return n.util.clone(e)})}return e}},languages:{extend:function(e,t){var a=n.util.clone(n.languages[e]);for(var r in t)a[r]=t[r];return a},insertBefore:function(e,t,a,r){r=r||n.languages;var l=r[e];if(2==arguments.length){a=arguments[1];for(var i in a)a.hasOwnProperty(i)&&(l[i]=a[i]);return l}var o={};for(var s in l)if(l.hasOwnProperty(s)){if(s==t)for(var i in a)a.hasOwnProperty(i)&&(o[i]=a[i]);o[s]=l[s]}return n.languages.DFS(n.languages,function(t,n){n===r[e]&&t!=e&&(this[t]=o)}),r[e]=o},DFS:function(e,t,a,r){r=r||{};for(var l in e)e.hasOwnProperty(l)&&(t.call(e,l,e[l],a||l),"Object"!==n.util.type(e[l])||r[n.util.objId(e[l])]?"Array"!==n.util.type(e[l])||r[n.util.objId(e[l])]||(r[n.util.objId(e[l])]=!0,n.languages.DFS(e[l],t,l,r)):(r[n.util.objId(e[l])]=!0,n.languages.DFS(e[l],t,null,r)))}},plugins:{},highlightAll:function(e,t){var a={callback:t,selector:'code[class*="language-"], [class*="language-"] code, code[class*="lang-"], [class*="lang-"] code'};n.hooks.run("before-highlightall",a);for(var r,l=a.elements||document.querySelectorAll(a.selector),i=0;r=l[i++];)n.highlightElement(r,e===!0,a.callback)},highlightElement:function(t,a,r){for(var l,i,o=t;o&&!e.test(o.className);)o=o.parentNode;o&&(l=(o.className.match(e)||[,""])[1],i=n.languages[l]),t.className=t.className.replace(e,"").replace(/\s+/g," ")+" language-"+l,o=t.parentNode,/pre/i.test(o.nodeName)&&(o.className=o.className.replace(e,"").replace(/\s+/g," ")+" language-"+l);var s=t.textContent,u={element:t,language:l,grammar:i,code:s};if(!s||!i)return n.hooks.run("complete",u),void 0;if(n.hooks.run("before-highlight",u),a&&_self.Worker){var c=new Worker(n.filename);c.onmessage=function(e){u.highlightedCode=e.data,n.hooks.run("before-insert",u),u.element.innerHTML=u.highlightedCode,r&&r.call(u.element),n.hooks.run("after-highlight",u),n.hooks.run("complete",u)},c.postMessage(JSON.stringify({language:u.language,code:u.code,immediateClose:!0}))}else u.highlightedCode=n.highlight(u.code,u.grammar,u.language),n.hooks.run("before-insert",u),u.element.innerHTML=u.highlightedCode,r&&r.call(t),n.hooks.run("after-highlight",u),n.hooks.run("complete",u)},highlight:function(e,t,r){var l=n.tokenize(e,t);return a.stringify(n.util.encode(l),r)},tokenize:function(e,t){var a=n.Token,r=[e],l=t.rest;if(l){for(var i in l)t[i]=l[i];delete t.rest}e:for(var i in t)if(t.hasOwnProperty(i)&&t[i]){var o=t[i];o="Array"===n.util.type(o)?o:[o];for(var s=0;s<o.length;++s){var u=o[s],c=u.inside,g=!!u.lookbehind,h=!!u.greedy,f=0,d=u.alias;u=u.pattern||u;for(var p=0;p<r.length;p++){var m=r[p];if(r.length>e.length)break e;if(!(m instanceof a)){u.lastIndex=0;var y=u.exec(m),v=1;if(!y&&h&&p!=r.length-1){var b=r[p+1].matchedStr||r[p+1],k=m+b;if(p<r.length-2&&(k+=r[p+2].matchedStr||r[p+2]),u.lastIndex=0,y=u.exec(k),!y)continue;var w=y.index+(g?y[1].length:0);if(w>=m.length)continue;var _=y.index+y[0].length,P=m.length+b.length;if(v=3,P>=_){if(r[p+1].greedy)continue;v=2,k=k.slice(0,P)}m=k}if(y){g&&(f=y[1].length);var w=y.index+f,y=y[0].slice(f),_=w+y.length,S=m.slice(0,w),O=m.slice(_),j=[p,v];S&&j.push(S);var A=new a(i,c?n.tokenize(y,c):y,d,y,h);j.push(A),O&&j.push(O),Array.prototype.splice.apply(r,j)}}}}}return r},hooks:{all:{},add:function(e,t){var a=n.hooks.all;a[e]=a[e]||[],a[e].push(t)},run:function(e,t){var a=n.hooks.all[e];if(a&&a.length)for(var r,l=0;r=a[l++];)r(t)}}},a=n.Token=function(e,t,n,a,r){this.type=e,this.content=t,this.alias=n,this.matchedStr=a||null,this.greedy=!!r};if(a.stringify=function(e,t,r){if("string"==typeof e)return e;if("Array"===n.util.type(e))return e.map(function(n){return a.stringify(n,t,e)}).join("");var l={type:e.type,content:a.stringify(e.content,t,r),tag:"span",classes:["token",e.type],attributes:{},language:t,parent:r};if("comment"==l.type&&(l.attributes.spellcheck="true"),e.alias){var i="Array"===n.util.type(e.alias)?e.alias:[e.alias];Array.prototype.push.apply(l.classes,i)}n.hooks.run("wrap",l);var o="";for(var s in l.attributes)o+=(o?" ":"")+s+'="'+(l.attributes[s]||"")+'"';return"<"+l.tag+' class="'+l.classes.join(" ")+'" '+o+">"+l.content+"</"+l.tag+">"},!_self.document)return _self.addEventListener?(_self.addEventListener("message",function(e){var t=JSON.parse(e.data),a=t.language,r=t.code,l=t.immediateClose;_self.postMessage(n.highlight(r,n.languages[a],a)),l&&_self.close()},!1),_self.Prism):_self.Prism;var r=document.currentScript||[].slice.call(document.getElementsByTagName("script")).pop();return r&&(n.filename=r.src,document.addEventListener&&!r.hasAttribute("data-manual")&&document.addEventListener("DOMContentLoaded",n.highlightAll)),_self.Prism}();"undefined"!=typeof module&&module.exports&&(module.exports=Prism),"undefined"!=typeof global&&(global.Prism=Prism);
</script>

<script type="text/javascript">
Prism.languages.python={"triple-quoted-string":{pattern:/"""[\s\S]+?"""|'''[\s\S]+?'''/,alias:"string"},comment:{pattern:/(^|[^\\])#.*/,lookbehind:!0},string:/("|')(?:\\?.)*?\1/,"function":{pattern:/((?:^|\s)def[ \t]+)[a-zA-Z_][a-zA-Z0-9_]*(?=\()/g,lookbehind:!0},"class-name":{pattern:/(\bclass\s+)[a-z0-9_]+/i,lookbehind:!0},keyword:/\b(?:as|assert|async|await|break|class|continue|def|del|elif|else|except|exec|finally|for|from|global|if|import|in|is|lambda|pass|print|raise|return|try|while|with|yield)\b/,"boolean":/\b(?:True|False)\b/,number:/\b-?(?:0[bo])?(?:(?:\d|0x[\da-f])[\da-f]*\.?\d*|\.\d+)(?:e[+-]?\d+)?j?\b/i,operator:/[-+%=]=?|!=|\*\*?=?|\/\/?=?|<[<=>]?|>[=>]?|[&|^~]|\b(?:or|and|not)\b/,punctuation:/[{}[\];(),.:]/};
</script>

<script type="text/javascript">
!function(){"undefined"!=typeof self&&self.Prism&&self.document&&Prism.hooks.add("complete",function(e){if(e.code){var t=e.element.parentNode,s=/\s*\bline-numbers\b\s*/;if(t&&/pre/i.test(t.nodeName)&&(s.test(t.className)||s.test(e.element.className))&&!e.element.querySelector(".line-numbers-rows")){s.test(e.element.className)&&(e.element.className=e.element.className.replace(s,"")),s.test(t.className)||(t.className+=" line-numbers");var n,a=e.code.match(/\n(?!$)/g),l=a?a.length+1:1,m=new Array(l+1);m=m.join("<span></span>"),n=document.createElement("span"),n.className="line-numbers-rows",n.innerHTML=m,t.hasAttribute("data-start")&&(t.style.counterReset="linenumber "+(parseInt(t.getAttribute("data-start"),10)-1)),e.element.appendChild(n)}}})}();
</script>

<script type="text/javascript">
!function(){if("undefined"!=typeof self&&self.Prism&&self.document){var e={html:"HTML",xml:"XML",svg:"SVG",mathml:"MathML",css:"CSS",clike:"C-like",javascript:"JavaScript",abap:"ABAP",actionscript:"ActionScript",apacheconf:"Apache Configuration",apl:"APL",applescript:"AppleScript",asciidoc:"AsciiDoc",aspnet:"ASP.NET (C#)",autoit:"AutoIt",autohotkey:"AutoHotkey",basic:"BASIC",csharp:"C#",cpp:"C++",coffeescript:"CoffeeScript","css-extras":"CSS Extras",fsharp:"F#",glsl:"GLSL",http:"HTTP",inform7:"Inform 7",json:"JSON",latex:"LaTeX",lolcode:"LOLCODE",matlab:"MATLAB",mel:"MEL",nasm:"NASM",nginx:"nginx",nsis:"NSIS",objectivec:"Objective-C",ocaml:"OCaml",parigp:"PARI/GP",php:"PHP","php-extras":"PHP Extras",powershell:"PowerShell",jsx:"React JSX",rest:"reST (reStructuredText)",sas:"SAS",sass:"Sass (Sass)",scss:"Sass (Scss)",sql:"SQL",typescript:"TypeScript",vhdl:"VHDL",vim:"vim",wiki:"Wiki markup",yaml:"YAML"};Prism.hooks.add("before-highlight",function(s){var a=s.element.parentNode;if(a&&/pre/i.test(a.nodeName)){var t,i,r=a.getAttribute("data-language")||e[s.language]||s.language.substring(0,1).toUpperCase()+s.language.substring(1),l=a.previousSibling;l&&/\s*\bprism-show-language\b\s*/.test(l.className)&&l.firstChild&&/\s*\bprism-show-language-label\b\s*/.test(l.firstChild.className)?i=l.firstChild:(t=document.createElement("div"),i=document.createElement("div"),i.className="prism-show-language-label",t.className="prism-show-language",t.appendChild(i),a.parentNode.insertBefore(t,a)),i.innerHTML=r}})}}();
</script>

<script type="text/x-mathjax-config">
(function () {

MathJax.Hub.Config({
	'showProcessingMessages': false,
	'messageStyle': 'none'
});

if (typeof MathJaxListener !== 'undefined') {
	MathJax.Hub.Register.StartupHook('End', function () {
		MathJaxListener.invokeCallbackForKey_('End');
	});
}

})();
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>


</body>

</html>
