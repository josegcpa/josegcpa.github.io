---
title: "LLMs can't innovate"
collection: blog_posts
description: |
    They sure can write gooder than me. But is innovation really their strongest suit? And most importantly - why does that matter? 
date: 2025-06-17
layout: post
note: false
tags: tech
---

A really interesting [result](https://mackinstitute.wharton.upenn.edu/2023/new-working-paper-finds-chatgpt-a-better-innovation-ideator-than-mba-students/): when rating how innovative product ideas are, people tend to rate those provided by ChatGPT more highly than those provided by people.

Equally interesting? The fact that all of these ideas - once you go through them - are of products *which already exist*.

This raises a pretty complicated question - when we evaluate how "creative" or "innovative" an LLM is (a corollary of the forever-sought out-of-domain generalization for generative methods), what is *actually* being rated?

To further complicate matters, and abstracting TS Kuhn's core idea in his "The Structure of Scientific Revolutions": people have a hard time seeing radical change as a legitimate option.

So, whatever innovation or creativity that comes from a human or an LLM is subject to a fundamental force (at least for product innovation): innovation has to be recognizable. In other words, it has to happen within a relatively narrow realm of possibilities.

A big LLM selling point is that they *can* innovate - see [OAI](https://www.technologyreview.com/2025/01/17/1110086/openai-has-created-an-ai-model-for-longevity-science/) and [Google's](https://ai.google.dev/gemini-api/docs/gemini-for-research) recent efforts in injecting their AI products in research endeavors. But when we look at hard data - [Subbarao Kambhampati's work](https://openreview.net/forum?id=FkKBxp0FhR) or [recent papers from Apple](https://ml-site.cdn-apple.com/papers/the-illusion-of-thinking.pdf) - we see clear evidence that LLMs cannot solve truly novel problems.

So why are we seeing this grand pursuit? My bet is on the - overblown - promises that the AI industry has made to justify their existence. Sam Altman has ["mused"](https://fortune.com/2025/04/03/recursion-pharmaceuticals-ai-drug-discovery/) that one day we might be able to ask ChatGPT to cure cancer. He also recently said that [AI will be able to solve climate change](https://time.com/7205596/sam-altman-superintelligence-agi/) while claiming that most of Earth's electricity [should eventually go to run AI](https://www.yahoo.com/news/sam-altman-says-significant-fraction-130703410.html?guccounter=1&guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS8). I think you get the point: there is no shortage of exaggerated claims to get funding. 

However, the kind of AI contributing to research - "solving cancer" or "saving the planet" - is not the kind of AI that Altman produces. The [AlphaFold protein structure database](https://alphafold.ebi.ac.uk/) (powered, you guessed it, by not-an-LLM [AlphaFold](https://deepmind.com/blog/article/putting-the-power-of-alphafold-into-the-worlds-hands)) is one such kind of an AI, providing pretty good predictions of how proteins look in three-dimensions. [GraphCast](https://deepmind.google/discover/blog/graphcast-ai-model-for-faster-and-more-accurate-global-weather-forecasting/) or [WeatherNext](https://deepmind.google/science/weathernext/) are not-an-LLM AI models which do a pretty good job at forecasting the weather. AI has also led to [enhanced drug development](https://www.nature.com/articles/s41591-024-03434-4) or to [improved medical image processing](https://www.nature.com/articles/s41467-024-44824-z). 

These are narrow applications - far from what attracts billions in funding. But they are capable of creating real value using AI (or similar) applications. Even in the age of agentic AI - where we expect LLMs to interact with one another - we will still require highly accurate tools which can be used to solve real-world problems. These tools will depend largely on specialist systems capable of solving specific problems with high fidelity - not on general intelligence (whatever that may end up being).

At the end of the day AI is already doing some pretty cool things! The vast majority, however, does not depend on the narrow definition of AI as text generation. And innovation - at least in the way that we, as people, can measure it, is not really a necessity for that.